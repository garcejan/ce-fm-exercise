{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Client Engineering: LLMs Test Exercises\n",
       "\n",
       "#### Exercise 1 - Text Cleaning\n",
       "\n",
       "Process the provided text samples by:\n",
       "- Remove URLs from the text: \"The link to latest football score. https://xyz.com/a/b\"\n",
       "- Remove alphanumeric words from the text: \"Hello Maria whatsup123\"\n",
       "- Remove words starting with '#' character: \"Mado is very good with last ball six #dhoni #six\"\n",
       "- Splits alphanumeric words into digits and text: \"I will be buying movie tickets for 4adults\"\n",
       "\n",
       "#### Exercise 2 - Summarization \n",
       "Use the text.csv file from the /data folder and summarize 3 of the stories using a model/technique of your choice \n",
       "\n",
       "#### Exercise 3 - Classification\n",
       "Use the provided Pytorch model from the /model folder and classify the text from all 3x stories chosen above (one by one).\n",
       "\n",
       "#### Exercise 4 - Performance\n",
       "Compare the summarized output of the article from /data and calculate the precision (BLEU score) taken into consideration the reference summary (summary-1-flan-ul2--article1) and the candidate summary (summary-2-flan-ul2--article1)\n",
       "\n",
       "**NOTE**:\n",
       "- You can provide your input within a Jupiter notebook containing the cells' output. Don't forget to be creative as much as you want in the provided time.\n",
       "- Please don't fork this repo.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "with open('README.md', 'r') as file:\n",
    "    readme_content = file.read()\n",
    "\n",
    "display(Markdown(readme_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Exercise 1\n",
    "Remove URLs from the text: \"The link to latest football score. https://xyz.com/a/b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output #1: The link to latest football score.\n",
      "Output #2: The link to latest football score. \n",
      "output #3: The link to latest football score. \n"
     ]
    }
   ],
   "source": [
    "text = \"The link to latest football score. https://xyz.com/a/b\"\n",
    "\n",
    "output1 = text[:-20]\n",
    "print(f'Output #1: {output1}')\n",
    "\n",
    "url_start = text.find('https://')\n",
    "output2 = text[:url_start]\n",
    "print(f'Output #2: {output2}')\n",
    "\n",
    "import re\n",
    "\n",
    "url_regex = r'https?://\\S+\\.\\S+'\n",
    "output3 = re.sub(url_regex, '', text)\n",
    "print(f'output #3: {output3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove alphanumeric words from the text: \"Hello Maria whatsup123\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Maria whatsup123\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello Maria whatsup123\"\n",
    "\n",
    "regex = r'\\b\\w*\\d\\w*\\b'\n",
    "output = re.sub(regex, '', text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove words starting with '#' character: \"Mado is very good with last ball six #dhoni #six\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mado is very good with last ball six #dhoni #six\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Mado is very good with last ball six #dhoni #six\"\n",
    "\n",
    "regex = r'\\s*#\\w+\\s*'\n",
    "output = re.sub(regex, '', text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits alphanumeric words into digits and text: \"I will be buying movie tickets for 4adults\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will be buying movie tickets for  4 adults\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"I will be buying movie tickets for 4adults\"\n",
    "\n",
    "regex = r'(\\d+|\\D+)'\n",
    "l_split = re.findall(regex, text)\n",
    "output = ' '.join(l_split)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Summarization\n",
    "Use the text.csv file from the /data folder and summarize 3 of the stories using a model/technique of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/text.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_labels = df.labels.unique()\n",
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blunkett tells of love and pain\\n\\nDavid Blunkett has spoken of his love for married publisher Kimberly Quinn for the first time.\\n\\nThe home secretary described how it affected his friends and personal life, but said he was a great believer in personal responsibility. Mr Blunkett is taking legal action to gain access to Mrs Quinn\\'s two-year-old son. She denies he is Mr Blunkett\\'s. The interview with BBC Radio Sheffield was made before allegations he fast-tracked a visa for Mrs Quinn\\'s nanny. The allegations, which he has denied, are being investigated by Sir Alan Budd. Mr Blunkett talked about how he fell in love - but that she resisted his desire to go public.\\n\\nIn an apparent reference to his court action to gain access to her son, he says he was a great believer in responsibility and consequences, even when they were painful. Mr Blunkett told BBC Radio Sheffield: \"I fell in love with someone and they wouldn\\'t go public and things started to go very badly wrong in the summer, and then the News of the World picked up the story. \"I tried for three years to make something work. \"I haven\\'t spoken about it and I don\\'t intend to. Even in the biography that\\'s being written about me I\\'ve ensured that there\\'s as little as possible.\" BBC political correspondent Carole Walker said the timing of the broadcast was unlikely to help his efforts to show that he is concentrating on getting on with the job of home secretary. Shadow home secretary David Davis says Mr Blunkett should quit if he is found to have influenced the visa process even indirectly.\\n\\nReports have claimed Mr Blunkett chaired a meeting to discuss delays in the visa system after he learned of nanny Leoncia Casalme\\'s wait. The Home Office has said it would be up to Sir Alan\\'s inquiry to decide if any such meeting was relevant. Home Office minister Fiona Mactaggart said she hoped Mr Blunkett would survive in his job. \"I work with him every day and I have always been surprised by how focused he is on the job in hand, on working to deal with things,\" she said. She told BBC One\\'s Breakfast with Frost programme: \"He is just really down for the job and I hope he does (survive).\"',\n",
       " 'Tories leave door open for Archer\\n\\nThe Conservative Party would deal \"sympathetically\" with any application by disgraced peer Lord Archer to rejoin its ranks, its co-chairman has said.\\n\\nDr Liam Fox told BBC One\\'s Breakfast with Frost programme there was no place for \"vindictiveness\" in politics. Lord Archer spent two years in prison after being convicted of perjury and perverting the course of justice. The former Tory deputy chairman\\'s five-year suspension from the party has just elapsed.\\n\\nA jury ruled that Lord Archer lied during a libel trial against the Daily Star at the High Court in London in 1987.\\n\\nHe won damages after the newspaper printed allegations about involvement with a prostitute. Dr Fox was asked if he would say yes or no if Lord Archer applied to rejoin. \"I\\'m sure that in line with people having served their sentence and having done some reparations for what they did wrong, we would look at that sympathetically. \"I don\\'t believe in vindictiveness, I don\\'t think that has any place in politics, unlike the prime minister and Alastair Campbell.\"\\n\\nTory peer Lord Tebbit said he agreed with Dr Fox\\'s view, and said the case should be looked at on its merits. \"After all, he is far from being the worst perjurer in the world,\" he added. Meanwhile, senior Conservative MP Sir Teddy Taylor warned that moves bring Lord Archer back into the fold could be controversial. He said: \"I suppose, on a Sunday in particular, we should always make provision for forgiving sinners. But there is no doubt it would be controversial.\" Lord Archer, who was not available for comment, remains a popular figure among constituency Tory parties and is a successful fundraiser. He has not been seen in the House of Lords since his release from prison in July 2003, although there is nothing in the rules to prevent him from attending.',\n",
       " \"Rock star sued by ex-girlfriend\\n\\nMotley Crue guitarist Mick Mars is being sued by his ex-girlfriend for $10 million (£5.4 million), claiming he broke a promise to take care of her.\\n\\nThe woman, Robin Mantooth, said Mars promised her repeatedly that he would provide financial support in the event of the couple breaking up. When they split in December, Mantooth says Mars denied any such agreement. She is asking a Los Angeles court to award her half the musician's property, a monthly allowance and damages. Mantooth added that the pair became lovers in 1990, after which she abandoned her career as a documentary film-maker to move in with the guitarist at his Malibu home.\\n\\nShe is also claiming that Mars, 53, has failed to provide her with any material support since they ceased to be a couple. Motley Crue recently reunited after being apart for a period of five years. They originally formed in the early 1980s and scored six hits in the UK, including Girls Girls Girls in 1987. They are embarking on a world tour later this year which will take in 60 cities across the US, Europe, Asia and Australia. Mars - real name Bob Allen Deal - underwent hip replacement surgery in October. He suffers from a degenerative rheumatic disease which causes ligaments and tendons to attach to the bone.\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.seed(13)\n",
    "nums = random.sample(range(1, df.shape[0]), 3)\n",
    "\n",
    "articles = df.loc[nums].text.to_list()\n",
    "article_labels = df.loc[nums].labels.to_list()\n",
    "articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221dafc94e314a7da4a4a55a506bdbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ae75c7a2e641b4afa89387545468da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b82317e716421ba001eaad61caf05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b160aa2a6bd54b2baf37caf92d248db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed2c456a58b4c02995280cae5e5f9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = []\n",
    "for article in articles:\n",
    "    summaries.append(summarizer(article, max_length=150, min_length=20, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'summary_text': \" Blunkett tells of love and pain but says he is a great believer in responsibility and consequences . Interview made before allegations he fast-tracked a visa for Quinn's nanny .\"}],\n",
       " [{'summary_text': ' Lord Archer spent two years in prison after being convicted of perjury and perverting the course of justice . Former Tory deputy chairman\\'s five-year suspension from the party has just elapsed . Dr Liam Fox said there was no place for \"vindictiveness\" in politics .'}],\n",
       " [{'summary_text': \" Motley Crue guitarist is being sued by his ex-girlfriend for $10 million (£5.4 million) Robin Mantooth claims he broke a promise to take care of her . She is asking a Los Angeles court to award her half the musician's property and damages .\"}]]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize \n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ZZ082W668\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ZZ082W668\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "stop_words = stopwords.words('english')\n",
    "punctuation = punctuation + '\\n\\t\\r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_word_frequencies(word_list):\n",
    "    word_freq = Counter(word_list)\n",
    "    return word_freq\n",
    "\n",
    "def weight_frequencies(word_frequencies):\n",
    "    max_frequency = max(word_frequencies.values())\n",
    "    \n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = word_frequencies[word]/max_frequency\n",
    "    return word_frequencies\n",
    "\n",
    "def sentence_score(sent_token, word_frequencies):\n",
    "    word_frequencies_lower = {word.lower(): freq for word, freq in word_frequencies.items()}\n",
    "    \n",
    "    sentence_scores = {}\n",
    "    for sent in sent_token:\n",
    "        sentence_words_lower = set(sent.lower().split(\" \"))\n",
    "        \n",
    "        # calculate score\n",
    "        sentence_score = sum(word_frequencies_lower.get(word, 0) for word in sentence_words_lower)\n",
    "        \n",
    "        # store score\n",
    "        sentence_scores[sent] = sentence_score\n",
    "    \n",
    "    return sentence_scores\n",
    "\n",
    "\n",
    "\n",
    "def get_summary(sent_token, sentence_scores):\n",
    "    select_length = int(len(sent_token)*0.3)\n",
    "    summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
    "    final_summary = [word for word in summary]\n",
    "    summary = ' '.join(final_summary)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr Blunkett told BBC Radio Sheffield: \"I fell in love with someone and they wouldn't go public and things started to go very badly wrong in the summer, and then the News of the World picked up the story. BBC political correspondent Carole Walker said the timing of the broadcast was unlikely to help his efforts to show that he is concentrating on getting on with the job of home secretary. \"I work with him every day and I have always been surprised by how focused he is on the job in hand, on working to deal with things,\" she said. Shadow home secretary David Davis says Mr Blunkett should quit if he is found to have influenced the visa process even indirectly. Mr Blunkett talked about how he fell in love - but that she resisted his desire to go public.\n",
      "Article len: [2157]\n",
      "Summary len: [759]\n",
      "------------------------------\n",
      "He has not been seen in the House of Lords since his release from prison in July 2003, although there is nothing in the rules to prevent him from attending. A jury ruled that Lord Archer lied during a libel trial against the Daily Star at the High Court in London in 1987. Tory peer Lord Tebbit said he agreed with Dr Fox's view, and said the case should be looked at on its merits. Lord Archer spent two years in prison after being convicted of perjury and perverting the course of justice.\n",
      "Article len: [2157]\n",
      "Summary len: [491]\n",
      "------------------------------\n",
      "Mantooth added that the pair became lovers in 1990, after which she abandoned her career as a documentary film-maker to move in with the guitarist at his Malibu home. Rock star sued by ex-girlfriend\n",
      "\n",
      "Motley Crue guitarist Mick Mars is being sued by his ex-girlfriend for $10 million (£5.4 million), claiming he broke a promise to take care of her. They are embarking on a world tour later this year which will take in 60 cities across the US, Europe, Asia and Australia.\n",
      "Article len: [2157]\n",
      "Summary len: [470]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for article in articles:\n",
    "    # nltk func\n",
    "    tokens = word_tokenize(article)\n",
    "    # compute frequencies   \n",
    "    word_frequencies = compute_word_frequencies(tokens)\n",
    "    # normalize frequencies\n",
    "    word_frequencies = weight_frequencies(word_frequencies)\n",
    "    # nltk func\n",
    "    sent_token = sent_tokenize(article)\n",
    "    # compute words' score in sentences\n",
    "    sentence_scores = sentence_score(sent_token, word_frequencies)\n",
    "\n",
    "    summary = get_summary(sent_token, sentence_scores)\n",
    "\n",
    "    print(summary)\n",
    "    print(f'Article len: [{len(articles[0])}]')\n",
    "    print(f'Summary len: [{len(summary)}]')\n",
    "    print('---'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Classification\n",
    "Use the provided Pytorch model from the /model folder and classify the text from all 3x stories chosen above (one by one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You seem to have cloned a repository without having git-lfs installed. Please install git-lfs and run `git lfs install` followed by `git lfs pull` in the folder you cloned.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ZZ082W668\\Anaconda3\\envs\\env\\lib\\site-packages\\transformers\\modeling_utils.py:460\u001b[0m, in \u001b[0;36mload_state_dict\u001b[1;34m(checkpoint_file)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(checkpoint_file, map_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    461\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ZZ082W668\\Anaconda3\\envs\\env\\lib\\site-packages\\torch\\serialization.py:815\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> 815\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32mc:\\Users\\ZZ082W668\\Anaconda3\\envs\\env\\lib\\site-packages\\torch\\serialization.py:1033\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1029\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1030\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived object of type \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(f)\u001b[39m}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1031\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfunctionality.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1033\u001b[0m magic_number \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1034\u001b[0m \u001b[39mif\u001b[39;00m magic_number \u001b[39m!=\u001b[39m MAGIC_NUMBER:\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, 'v'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ZZ082W668\\Documents\\IBM\\ce-fm-exercise-main\\exercise.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ZZ082W668/Documents/IBM/ce-fm-exercise-main/exercise.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ZZ082W668/Documents/IBM/ce-fm-exercise-main/exercise.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_path)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ZZ082W668/Documents/IBM/ce-fm-exercise-main/exercise.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSequenceClassification\u001b[39m.\u001b[39;49mfrom_pretrained(model_path)\n",
      "File \u001b[1;32mc:\\Users\\ZZ082W668\\Anaconda3\\envs\\env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:493\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    492\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    494\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    495\u001b[0m     )\n\u001b[0;32m    496\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    497\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ZZ082W668\\Anaconda3\\envs\\env\\lib\\site-packages\\transformers\\modeling_utils.py:2629\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2626\u001b[0m \u001b[39mif\u001b[39;00m from_pt:\n\u001b[0;32m   2627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sharded \u001b[39mand\u001b[39;00m state_dict \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2628\u001b[0m         \u001b[39m# Time to load the checkpoint\u001b[39;00m\n\u001b[1;32m-> 2629\u001b[0m         state_dict \u001b[39m=\u001b[39m load_state_dict(resolved_archive_file)\n\u001b[0;32m   2631\u001b[0m     \u001b[39m# set dtype to instantiate the model under:\u001b[39;00m\n\u001b[0;32m   2632\u001b[0m     \u001b[39m# 1. If torch_dtype is not None, we use that dtype\u001b[39;00m\n\u001b[0;32m   2633\u001b[0m     \u001b[39m# 2. If torch_dtype is \"auto\", we auto-detect dtype from the loaded state_dict, by checking its first\u001b[39;00m\n\u001b[0;32m   2634\u001b[0m     \u001b[39m#    weights entry that is of a floating type - we assume all floating dtype weights are of the same dtype\u001b[39;00m\n\u001b[0;32m   2635\u001b[0m     \u001b[39m# we also may have config.torch_dtype available, but we won't rely on it till v5\u001b[39;00m\n\u001b[0;32m   2636\u001b[0m     dtype_orig \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ZZ082W668\\Anaconda3\\envs\\env\\lib\\site-packages\\transformers\\modeling_utils.py:465\u001b[0m, in \u001b[0;36mload_state_dict\u001b[1;34m(checkpoint_file)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(checkpoint_file) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    464\u001b[0m     \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mread(\u001b[39m7\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 465\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m    466\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou seem to have cloned a repository without having git-lfs installed. Please install \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    467\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgit-lfs and run `git lfs install` followed by `git lfs pull` in the folder \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    468\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myou cloned.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    469\u001b[0m         )\n\u001b[0;32m    470\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    471\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    472\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to locate the file \u001b[39m\u001b[39m{\u001b[39;00mcheckpoint_file\u001b[39m}\u001b[39;00m\u001b[39m which is necessary to load this pretrained \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    473\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmodel. Make sure you have saved the model properly.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    474\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: You seem to have cloned a repository without having git-lfs installed. Please install git-lfs and run `git lfs install` followed by `git lfs pull` in the folder you cloned."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = './model'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-storage-and-bandwidth-usage\n",
    "\n",
    "![Sample Image](git_error.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('zero-shot-classification')\n",
    "# classifier = pipeline('zero-shot-classification', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for article in articles:\n",
    "    results.append(classifier(article, candidate_labels = article_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred label: [politics] | True label: [politics]\n",
      "Pred label: [politics] | True label: [politics]\n",
      "Pred label: [business] | True label: [entertainment]\n"
     ]
    }
   ],
   "source": [
    "for article, article_label in zip(results, article_labels):\n",
    "    pred_label = article['labels'][0]    \n",
    "    print(f'Pred label: [{pred_label}] | True label: [{article_label}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Blunkett tells of love and pain\\n\\nDavid Blunkett has spoken of his love for married publisher Kimberly Quinn for the first time.\\n\\nThe home secretary described how it affected his friends and personal life, but said he was a great believer in personal responsibility. Mr Blunkett is taking legal action to gain access to Mrs Quinn\\'s two-year-old son. She denies he is Mr Blunkett\\'s. The interview with BBC Radio Sheffield was made before allegations he fast-tracked a visa for Mrs Quinn\\'s nanny. The allegations, which he has denied, are being investigated by Sir Alan Budd. Mr Blunkett talked about how he fell in love - but that she resisted his desire to go public.\\n\\nIn an apparent reference to his court action to gain access to her son, he says he was a great believer in responsibility and consequences, even when they were painful. Mr Blunkett told BBC Radio Sheffield: \"I fell in love with someone and they wouldn\\'t go public and things started to go very badly wrong in the summer, and then the News of the World picked up the story. \"I tried for three years to make something work. \"I haven\\'t spoken about it and I don\\'t intend to. Even in the biography that\\'s being written about me I\\'ve ensured that there\\'s as little as possible.\" BBC political correspondent Carole Walker said the timing of the broadcast was unlikely to help his efforts to show that he is concentrating on getting on with the job of home secretary. Shadow home secretary David Davis says Mr Blunkett should quit if he is found to have influenced the visa process even indirectly.\\n\\nReports have claimed Mr Blunkett chaired a meeting to discuss delays in the visa system after he learned of nanny Leoncia Casalme\\'s wait. The Home Office has said it would be up to Sir Alan\\'s inquiry to decide if any such meeting was relevant. Home Office minister Fiona Mactaggart said she hoped Mr Blunkett would survive in his job. \"I work with him every day and I have always been surprised by how focused he is on the job in hand, on working to deal with things,\" she said. She told BBC One\\'s Breakfast with Frost programme: \"He is just really down for the job and I hope he does (survive).\"',\n",
       "  'labels': ['politics', 'business', 'tech', 'entertainment', 'sport'],\n",
       "  'scores': [0.5483059883117676,\n",
       "   0.2615046203136444,\n",
       "   0.0874328762292862,\n",
       "   0.07312867045402527,\n",
       "   0.029627768322825432]},\n",
       " {'sequence': 'Tories leave door open for Archer\\n\\nThe Conservative Party would deal \"sympathetically\" with any application by disgraced peer Lord Archer to rejoin its ranks, its co-chairman has said.\\n\\nDr Liam Fox told BBC One\\'s Breakfast with Frost programme there was no place for \"vindictiveness\" in politics. Lord Archer spent two years in prison after being convicted of perjury and perverting the course of justice. The former Tory deputy chairman\\'s five-year suspension from the party has just elapsed.\\n\\nA jury ruled that Lord Archer lied during a libel trial against the Daily Star at the High Court in London in 1987.\\n\\nHe won damages after the newspaper printed allegations about involvement with a prostitute. Dr Fox was asked if he would say yes or no if Lord Archer applied to rejoin. \"I\\'m sure that in line with people having served their sentence and having done some reparations for what they did wrong, we would look at that sympathetically. \"I don\\'t believe in vindictiveness, I don\\'t think that has any place in politics, unlike the prime minister and Alastair Campbell.\"\\n\\nTory peer Lord Tebbit said he agreed with Dr Fox\\'s view, and said the case should be looked at on its merits. \"After all, he is far from being the worst perjurer in the world,\" he added. Meanwhile, senior Conservative MP Sir Teddy Taylor warned that moves bring Lord Archer back into the fold could be controversial. He said: \"I suppose, on a Sunday in particular, we should always make provision for forgiving sinners. But there is no doubt it would be controversial.\" Lord Archer, who was not available for comment, remains a popular figure among constituency Tory parties and is a successful fundraiser. He has not been seen in the House of Lords since his release from prison in July 2003, although there is nothing in the rules to prevent him from attending.',\n",
       "  'labels': ['politics', 'tech', 'business', 'entertainment', 'sport'],\n",
       "  'scores': [0.6381965279579163,\n",
       "   0.14595063030719757,\n",
       "   0.10945958644151688,\n",
       "   0.07113103568553925,\n",
       "   0.035262297838926315]},\n",
       " {'sequence': \"Rock star sued by ex-girlfriend\\n\\nMotley Crue guitarist Mick Mars is being sued by his ex-girlfriend for $10 million (£5.4 million), claiming he broke a promise to take care of her.\\n\\nThe woman, Robin Mantooth, said Mars promised her repeatedly that he would provide financial support in the event of the couple breaking up. When they split in December, Mantooth says Mars denied any such agreement. She is asking a Los Angeles court to award her half the musician's property, a monthly allowance and damages. Mantooth added that the pair became lovers in 1990, after which she abandoned her career as a documentary film-maker to move in with the guitarist at his Malibu home.\\n\\nShe is also claiming that Mars, 53, has failed to provide her with any material support since they ceased to be a couple. Motley Crue recently reunited after being apart for a period of five years. They originally formed in the early 1980s and scored six hits in the UK, including Girls Girls Girls in 1987. They are embarking on a world tour later this year which will take in 60 cities across the US, Europe, Asia and Australia. Mars - real name Bob Allen Deal - underwent hip replacement surgery in October. He suffers from a degenerative rheumatic disease which causes ligaments and tendons to attach to the bone.\",\n",
       "  'labels': ['business', 'entertainment', 'tech', 'sport', 'politics'],\n",
       "  'scores': [0.32575523853302,\n",
       "   0.3162887692451477,\n",
       "   0.22601090371608734,\n",
       "   0.07499825209379196,\n",
       "   0.056946806609630585]}]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Performance\n",
    "Compare the summarized output of the article from /data and calculate the precision (BLEU score) taken into consideration the reference summary (summary-1-flan-ul2--article1) and the candidate summary (summary-2-flan-ul2--article1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People are using AI chatbots to fill junk websites with AI-generated text that attracts paying advertisers, according to a new report from the media research organization NewsGuard that was shared exclusively with MIT Technology Review. Over 140 major brands are paying for ads that end up on unreliable AI-written sites, likely without their knowledge. Ninety percent of the ads from major brands found on these AI-generated news sites were served by Google, though the company’s own policies prohibit sites from placing Google-served ads on pages that include “spammy automatically generated content.” The practice threatens to hasten the arrival of a glitchy, spammy internet that is overrun by AI-generated content, as well as wasting massive amounts of ad money.\n",
      "\n",
      "A new report finds that sites run with AI-generated content serve ads from major brands, which mostly come from Google. Some of those sites contained dangerous misinformation. And this is just getting started. More could be on the way. \"The opaque nature of programmatic advertising has inadvertently turned major brands into unwitting supporters.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/summary-1-flan-ul2--article1.txt', 'r') as file:\n",
    "    reference_summary = file.read()\n",
    "\n",
    "with open('data/summary-2-flan-ul2--article1.txt', 'r') as file:\n",
    "    candidate_summary = file.read()\n",
    "\n",
    "print(reference_summary)\n",
    "print(candidate_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score 1.0025117266892697e-231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZZ082W668\\Anaconda3\\envs\\env\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\ZZ082W668\\Anaconda3\\envs\\env\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\ZZ082W668\\Anaconda3\\envs\\env\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "bleu = sentence_bleu(reference_summary, candidate_summary)\n",
    "print(f'BLEU score {bleu}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score with smoothing: 0.0027240282824459398\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "bleu = sentence_bleu(reference_summary, candidate_summary, smoothing_function=smoothie)\n",
    "print(f'BLEU score with smoothing: {bleu}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
